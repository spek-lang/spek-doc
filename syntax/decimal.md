# decimal

A **decimal** is a value type which stores a signed 128-bit value.

| Precision | Default |
| -- | -- |
| 28-29 significant digits | 0 |

| Minimum | Maximum |
| -- | -- | -- |
| -79228162514264337593543950335 | 79228162514264337593543950335 |
| -7.9 x 10^28 | 7.9 x 10^28 |   |


The decimal type is more precise than the float data type and smaller range which makes it more favorable for scenarios which involve financial calculations.
